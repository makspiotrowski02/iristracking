{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import json\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import time\n",
    "import uuid\n",
    "import albumentations as alb\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Input, Conv2D, Reshape, Dropout\n",
    "from keras.applications import ResNet152V2\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating preparing and augmenting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path where images will be saved and how many of them\n",
    "IMAGES_PATH = os.path.join('data','images')\n",
    "number_of_images = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to take the photos\n",
    "def take_photos(number_of_images):\n",
    "    capture =cv2.VideoCapture(0) # Choose the device\n",
    "    for n in range(number_of_images):\n",
    "        print(\"Getting image {}\".format(n))\n",
    "        ret,frame = capture.read()\n",
    "        image_name = os.path.join(IMAGES_PATH,f'{str(uuid.uuid1())}.jpg')\n",
    "        cv2.imwrite(image_name, frame)\n",
    "        cv2.imshow('frame',frame)\n",
    "        time.sleep(0.5)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    capture.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "take_photos(number_of_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Launch the app to label the data\n",
    "!labelme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading images\n",
    "def  load_image(path):\n",
    "    byte_image = tf.io.read_file(path)\n",
    "    image = tf.io.decode_jpeg(byte_image)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = tf.data.Dataset.list_files('data\\\\images\\\\*.jpg',shuffle=False)\n",
    "images = images.map(load_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Viewing example images\n",
    "image_generator = images.batch(4).as_numpy_iterator()\n",
    "plot_images = image_generator.next()\n",
    "\n",
    "fig,ax = plt.subplots(ncols=4, figsize=(20,20))\n",
    "for idx, image in enumerate(plot_images):\n",
    "    ax[idx].imshow(image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Test': 62.99999999999999}\n",
      "{'Train': 13.5}\n",
      "{'Val': 13.5}\n"
     ]
    }
   ],
   "source": [
    "# Calculating how many images for train, test and val\n",
    "print({'Test': 3 * number_of_images  *.7}) \n",
    "print({'Train': 3 * number_of_images  *.15})\n",
    "print({'Val': 3 * number_of_images  *.15})  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Moving labels after manually moving images to set folders\n",
    "for folder in ['train','test','val']:\n",
    "    for file in os.listdir(os.path.join('data',folder, 'images')):\n",
    "\n",
    "        name = file.split('.')[0]+'.json'\n",
    "        existing_filepath = os.path.join('data','labels', name)\n",
    "        \n",
    "        if os.path.exists(existing_filepath):\n",
    "            new_filepath = os.path.join('data',folder,'labels',name)\n",
    "            os.replace(existing_filepath, new_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating augmentor for data augmentation\n",
    "augmentor = alb.Compose([alb.RandomCrop(width=450,height=450),\n",
    "                         alb.HorizontalFlip(p=0.5),\n",
    "                         alb.RandomBrightnessContrast(p=0.3),\n",
    "                         alb.RandomGamma(p=0.3),\n",
    "                         alb.RGBShift(p=0.3),\n",
    "                         alb.VerticalFlip(p=0.5)],\n",
    "                         keypoint_params=alb.KeypointParams(format='xy', \n",
    "                                                    label_fields=['class_labels']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "for partition in ['train', 'test', 'val']: \n",
    "    for file in os.listdir(os.path.join('data', partition, 'images')):\n",
    "        image = cv2.imread(os.path.join('data', partition, 'images', file))\n",
    "\n",
    "        classes = [0,0]\n",
    "        coordinates = [0,0,0.00001,0.00001]\n",
    "        label_path = os.path.join('data', partition, 'labels', f'{file.split(\".\")[0]}.json')\n",
    "        if os.path.exists(label_path):\n",
    "            with open(label_path, 'r') as f:\n",
    "                label = json.load(f)\n",
    "    \n",
    "            if label['shapes'][0]['label']=='LeftEye': \n",
    "                classes[0] = 1\n",
    "                coordinates[0] = np.squeeze(label['shapes'][0]['points'])[0]\n",
    "                coordinates[1] = np.squeeze(label['shapes'][0]['points'])[1]\n",
    "\n",
    "            if label['shapes'][0]['label']=='RightEye':\n",
    "                classes[1] = 1\n",
    "                coordinates[2] = np.squeeze(label['shapes'][0]['points'])[0]\n",
    "                coordinates[3] = np.squeeze(label['shapes'][0]['points'])[1]\n",
    "\n",
    "            if len(label['shapes']) > 1:     \n",
    "                if label['shapes'][1]['label'] =='LeftEye': \n",
    "                    classes[0] = 1 \n",
    "                    coordinates[0] = np.squeeze(label['shapes'][1]['points'])[0]\n",
    "                    coordinates[1] = np.squeeze(label['shapes'][1]['points'])[1]\n",
    "\n",
    "                if label['shapes'][1]['label'] =='RightEye': \n",
    "                    classes[1] = 1\n",
    "                    coordinates[2] = np.squeeze(label['shapes'][1]['points'])[0]\n",
    "                    coordinates[3] = np.squeeze(label['shapes'][1]['points'])[1]\n",
    "            \n",
    "            np.divide(coordinates, [640,480,640,480])\n",
    "                \n",
    "        try: \n",
    "            for x in range(120):\n",
    "                keypoints = [(coordinates[:2]), (coordinates[2:])]\n",
    "                augmented = augmentor(image=image, keypoints=keypoints, class_labels=['LeftEye','RightEye'])\n",
    "                cv2.imwrite(os.path.join('aug_data', partition, 'images', f'{file.split(\".\")[0]}.{x}.jpg'), augmented['image'])\n",
    "\n",
    "                annotation = {}\n",
    "                annotation['image'] = file\n",
    "                annotation['class'] = [0,0]\n",
    "                annotation['keypoints'] = [0,0,0,0]\n",
    "\n",
    "                if os.path.exists(label_path):\n",
    "                    if len(augmented['keypoints']) > 0: \n",
    "                        for id, cl in enumerate(augmented['class_labels']):\n",
    "                            if cl == 'LeftEye': \n",
    "                                annotation['class'][0] = 1 \n",
    "                                annotation['keypoints'][0] = augmented['keypoints'][id][0]\n",
    "                                annotation['keypoints'][1] = augmented['keypoints'][id][1]\n",
    "                            if cl == 'RightEye': \n",
    "                                annotation['class'][1] = 1 \n",
    "                                annotation['keypoints'][2] = augmented['keypoints'][id][0]\n",
    "                                annotation['keypoints'][3] = augmented['keypoints'][id][1]\n",
    "                                \n",
    "                annotation['keypoints'] = list(np.divide(annotation['keypoints'], [450,450,450,450]))\n",
    "\n",
    "\n",
    "                with open(os.path.join('aug_data', partition, 'labels', f'{file.split(\".\")[0]}.{x}.json'), 'w') as f:\n",
    "                    json.dump(annotation, f)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resizing and normalizing images\n",
    "def map_and_load_images(path):\n",
    "    image_set = tf.data.Dataset.list_files(path, shuffle=False)\n",
    "    image_set = image_set.map(load_image, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    image_set = image_set.map(lambda x: tf.image.resize(x, (250,250)), num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    image_set = image_set.map(lambda x: x/255, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    return image_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_labels(label_path):\n",
    "    with open(label_path.numpy(), 'r', encoding=\"utf-8\") as f:\n",
    "        label = json.load(f)\n",
    "    return [label['keypoints']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading labels\n",
    "def map_and_load_labels(path):\n",
    "    label_set = tf.data.Dataset.list_files(path, shuffle=False)\n",
    "    label_set = label_set.map(lambda x: tf.py_function(load_labels, [x], [tf.float16]))\n",
    "    return label_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating sets\n",
    "def create_set(images, labels, n_shuffle):\n",
    "    set = tf.data.Dataset.zip((images, labels))\n",
    "    set = set.shuffle(n_shuffle)\n",
    "    set = set.batch(16, drop_remainder=True)\n",
    "    set = set.prefetch(4)\n",
    "    return set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = map_and_load_images('aug_data\\\\train\\\\images\\\\*.jpg')\n",
    "test_images = map_and_load_images('aug_data\\\\test\\\\images\\\\*.jpg')\n",
    "val_images = map_and_load_images('aug_data\\\\val\\\\images\\\\*.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = map_and_load_labels('aug_data\\\\train\\\\labels\\\\*.json')\n",
    "test_labels = map_and_load_labels('aug_data\\\\test\\\\labels\\\\*.json')\n",
    "val_labels = map_and_load_labels('aug_data\\\\val\\\\labels\\\\*.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = create_set(train_images, train_labels, 7800)\n",
    "test = create_set(test_images, test_labels, 1800)\n",
    "val = create_set(val_images, val_labels, 1800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_samples = train.as_numpy_iterator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = data_samples.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 250, 250, 3)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(ncols=4, figsize=(20,20))\n",
    "for idx in range(4): \n",
    "    sample_image = res[0][idx].copy()\n",
    "    sample_coords = res[1][0][idx]\n",
    "    \n",
    "    cv2.circle(sample_image, tuple(np.multiply(sample_coords[:2], [250,250]).astype(int)), 2, (255,0,0), -1)\n",
    "    cv2.circle(sample_image, tuple(np.multiply(sample_coords[2:], [250,250]).astype(int)), 2, (255,0,0), -1)\n",
    "    \n",
    "    ax[idx].imshow(sample_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating, building and training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "iristracker_model = Sequential([\n",
    "    Input(shape=(250,250,3)), \n",
    "    ResNet152V2(include_top=False, input_shape=(250,250,3)),\n",
    "    Conv2D(512, 3, padding='same', activation='relu'),\n",
    "    Conv2D(512, 3, padding='same', activation='relu'),\n",
    "    Conv2D(256, 3, 2, padding='same', activation='relu'),\n",
    "    Conv2D(256, 2, 2, activation='relu'),\n",
    "    Dropout(0.05),\n",
    "    Conv2D(4, 2, 2),\n",
    "    Reshape((4,))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "loss = tf.keras.losses.MeanSquaredError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iristracker_model.compile(optimizer, loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do not run this cell, only for testing purposes\n",
    "\n",
    "class Iristracker(Model): \n",
    "    def __init__(self, iristracker_model,  **kwargs): \n",
    "        super().__init__(**kwargs)\n",
    "        self.model = iristracker_model\n",
    "\n",
    "    def compile(self, optimizer, custom_mean_squared_error, **kwargs):\n",
    "        super().compile(**kwargs)\n",
    "        self.custom_mean_squared_error = custom_mean_squared_error\n",
    "        self.optimizer = optimizer\n",
    "    \n",
    "\n",
    "    @tf.function\n",
    "    def train_step(self, batch, **kwargs): \n",
    "        \n",
    "        X, y = batch\n",
    "        y[0].set_shape((16, 4)) # Required to run\n",
    "\n",
    " \n",
    "        with tf.GradientTape() as tape: \n",
    "            coordinates = self.model(X, training=True)\n",
    "\n",
    "            loss = self.custom_mean_squared_error(tf.cast(y[0], tf.float32), coordinates) \n",
    "            \n",
    "            grad = tape.gradient(loss, self.model.trainable_variables)\n",
    "        \n",
    "        optimizer.apply_gradients(zip(grad, self.model.trainable_variables))\n",
    "        \n",
    "        return {\"loss\":loss}\n",
    "    \n",
    "    @tf.function\n",
    "    def test_step(self, batch, **kwargs): \n",
    "        X, y = batch\n",
    "        y[0].set_shape((16, 4))\n",
    "\n",
    "        coordinates = self.model(X, training=False)\n",
    "        \n",
    "\n",
    "        loss = self.custom_mean_squared_error(tf.cast(y[0], tf.float32), coordinates)\n",
    "\n",
    "        \n",
    "        return {\"total_loss\":loss}\n",
    "        \n",
    "    def call(self, X, **kwargs): \n",
    "        return self.model(X, **kwargs)\n",
    "model = Iristracker(iristracker_model)\n",
    "model.compile(optimizer,loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2779s\u001b[0m 6s/step - loss: 9.4979 - val_loss: 0.0000e+00\n",
      "Epoch 2/2\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2779s\u001b[0m 6s/step - loss: 6.3614 - val_loss: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(train, epochs=2, validation_data=val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(hist.history['loss'], color='green', label='loss')\n",
    "plt.plot(hist.history['val_loss'], color='blue', label='val loss')\n",
    "plt.suptitle('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = test.as_numpy_iterator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sample = test_data.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = model.predict(test_sample[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(ncols=4, figsize=(20,20))\n",
    "for id in range(4): \n",
    "    sample_image = test_sample[0][id]\n",
    "    sample_coords = yhat[id]\n",
    "    \n",
    "    cv2.circle(sample_image, tuple(np.multiply(sample_coords[:2], [250,250]).astype(int)), 2, (255,0,0), -1)\n",
    "    cv2.circle(sample_image, tuple(np.multiply(sample_coords[2:], [250,250]).astype(int)), 2, (0,255,0), -1)\n",
    "    \n",
    "    ax[id].imshow(sample_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('iristracker_resnet_v1.0.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "while cap.isOpened():\n",
    "    _ , frame = cap.read()\n",
    "    \n",
    "    frame = frame[50:500,50:500,:] \n",
    "    rgb_img = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    resized = cv2.resize(rgb_img, (250,250))\n",
    "    \n",
    "    yhat = model.predict(np.expand_dims(resized/255,0))\n",
    "    sample_coords = yhat[0,:4]\n",
    "    \n",
    "    cv2.circle(frame, tuple(np.multiply(sample_coords[:2], [450,450]).astype(int)), 2, (255,0,0), -1)\n",
    "    cv2.circle(frame, tuple(np.multiply(sample_coords[2:], [450,450]).astype(int)), 2, (0,255,0), -1)\n",
    "    \n",
    "    cv2.imshow('EyeTrack', frame)\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iristracking",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
